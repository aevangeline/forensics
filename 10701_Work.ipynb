{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10701 - Work",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aevangeline/forensics/blob/master/10701_Work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbNn34dodj8B",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Aurelia and Caroline - 10701"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei2_bEpaR2FO",
        "colab_type": "code",
        "outputId": "a8daa814-25f9-4a7e-c290-ee9933fbcdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s08zJMHfRgvB",
        "colab_type": "code",
        "outputId": "830ea9de-aeba-43c1-b059-9338a8a3874b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/cuda/10.0 nvidia-dali"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://developer.download.nvidia.com/compute/redist/cuda/10.0\n",
            "Requirement already satisfied: nvidia-dali in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nvidia-dali) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhJoenqRRrGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import pathlib\n",
        "from urllib.request import urlretrieve\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from os import remove\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil as sh\n",
        "import torch\n",
        "import glob\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import nvidia.dali.ops as ops\n",
        "import nvidia.dali.types as types\n",
        "from nvidia.dali.pipeline import Pipeline\n",
        "from nvidia.dali.plugin.pytorch import DALIClassificationIterator as PyTorchIterator\n",
        "from random import shuffle\n",
        "import math\n",
        "import time\n",
        "import copy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsHAEto1543H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FID_DIRECTORY = pathlib.Path(\"FID-300\")\n",
        "FID_LABELS = FID_DIRECTORY / \"label_table.csv\"\n",
        "FID_SOURCE_URL = \"https://fid.dmi.unibas.ch/FID-300.zip\"\n",
        "TRAIN_DIR = \"FID-300/references/\"\n",
        "TEST_DIR = \"FID-300/tracks_cropped/\"\n",
        "NUM_EPOCHS = 100\n",
        "NUM_CLASSES = 1175\n",
        "INPUT_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "MODEL_NAME = \"resnet\"\n",
        "FEATURE_EXTRACT=False\n",
        "USE_PRETRAINED=False\n",
        "db_folder = pathlib.Path(TRAIN_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsEh9EEYC4Ur",
        "colab_type": "code",
        "outputId": "b925359d-41bc-4356-8710-90d2ec5bdd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def fetch_FID_300_data():\n",
        "    \"\"\"Downloads and extracts FID-300 data to a local folder\"\"\"\n",
        "    if FID_DIRECTORY.exists():\n",
        "        print(\"FID-300 Database already exists\")\n",
        "        return\n",
        "    print(\"Downloading FID_300\")\n",
        "    local_file, _ = urlretrieve(FID_SOURCE_URL)\n",
        "    with ZipFile(local_file) as archive:\n",
        "        print(\"Extracting FID-300\")\n",
        "        archive.extractall()\n",
        "    remove(local_file)\n",
        "\n",
        "fetch_FID_300_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FID-300 Database already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojc6z_bs-Q1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExternalInputIterator(object):\n",
        "    def __init__(self, batch_size, image_dir, repeat = 32):\n",
        "        self.images_dir = pathlib.Path(image_dir)\n",
        "        self.images = list(glob.iglob(str(self.images_dir/\"*\"))) \n",
        "        self.batch_size = batch_size \n",
        "        self.repeat = repeat\n",
        "        self.queue = self.images * self.repeat\n",
        "        shuffle(self.queue)\n",
        "        self.i = 0  \n",
        "\n",
        "    def __iter__(self):\n",
        "        self.i = 0\n",
        "        shuffle(self.queue)\n",
        "        return self\n",
        "\n",
        "    @property\n",
        "    def size(self,):\n",
        "      return len(self.images) * self.repeat\n",
        "\n",
        "    def __next__(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        if self.i >= len(self.queue):\n",
        "          raise StopIteration\n",
        "        for _ in range(self.batch_size):\n",
        "          while self.i >= len(self.queue):\n",
        "            self.i -= 1\n",
        "          img = self.queue[self.i]\n",
        "          fname = pathlib.Path(img)\n",
        "          label = np.array(int(fname.stem) - 1, dtype = np.uint8)\n",
        "          with open(fname, 'rb') as f:\n",
        "            buff = np.frombuffer(f.read(), dtype = np.uint8)\n",
        "            batch.append(buff)\n",
        "          labels.append(label)\n",
        "          self.i += 1    \n",
        "        return (batch, labels)\n",
        "\n",
        "    next = __next__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3eIOKVQSMwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AugmentationPipeline(Pipeline):\n",
        "    def __init__(self, batch_size, num_threads, device_id = 0,\n",
        "                 examples_per_image = 1000, folder = db_folder,\n",
        "                 pipelined = True, exec_async = True):\n",
        "        super(AugmentationPipeline, self).__init__(batch_size, num_threads,\n",
        "                                                   device_id, seed = 12,\n",
        "                                                   exec_pipelined=pipelined,\n",
        "                                                   exec_async=exec_async)\n",
        "        self.external_data = ExternalInputIterator(batch_size,\n",
        "                                                   folder,\n",
        "                                                   examples_per_image)\n",
        "        self.input = ops.ExternalSource()\n",
        "        self.input_label = ops.ExternalSource()\n",
        "        self.iterator = iter(self.external_data)\n",
        "        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n",
        "            #random_aspect_ratio=[0.8, 1.25],\n",
        "            #random_area=[0.6, 1.0],\n",
        "            #num_attempts=100)\n",
        "        self.augmentations = {}\n",
        "        # input is sampled randomly for output pixel's neighbourhood\n",
        "        #self.augmentations[\"jitter\"] = (0.3, ops.Jitter(device = \"gpu\"))\n",
        "        # transforms sampling coordinates to produce wavy patterns\n",
        "        #self.augmentations[\"water\"] = (0.2, ops.Water(device = \"gpu\"))\n",
        "        # applies fisheye distortion\n",
        "        #self.augmentations[\"sphere\"] = (0.3, ops.Sphere(device = \"gpu\"))\n",
        "        # rotates the image, enlarging the canvas\n",
        "        self.rotation_rng = ops.Uniform(range=(-180.00, 180.00))\n",
        "        self.rotate = ops.Rotate(device = \"gpu\",\n",
        "                                 interp_type = types.INTERP_LINEAR,\n",
        "                                 fill_value = 0)\n",
        "        # param resizes the image so that the shorter edge is exactly 400px long\n",
        "        self.resize = ops.Resize(device = \"gpu\", resize_x = INPUT_SIZE, resize_y = INPUT_SIZE)\n",
        "        # param flips the image\n",
        "        self.flip_rng = ops.CoinFlip()\n",
        "        self.flip = ops.Flip(device = \"gpu\")\n",
        "        self.bri_con_rng = ops.Uniform(range = (.5, 2))\n",
        "        self.saturation_rng = ops.Uniform(range = (.2, 1))\n",
        "        self.color_twist = ops.ColorTwist(device = \"gpu\")\n",
        "        self.iter = 0\n",
        "\n",
        "    def define_graph(self):\n",
        "        self.jpegs = self.input(name=\"Reader\")\n",
        "        self.labels = self.input_label(name=\"Reader\")\n",
        "        output_labels = []\n",
        "        images = self.decode(self.jpegs).gpu()\n",
        "        transformed = images\n",
        "        for thresh, op in self.augmentations.values():\n",
        "          if random() < thresh:\n",
        "            transformed = op(images)\n",
        "        #transformed = self.flip(transformed,\n",
        "        #                        vertical = self.flip_rng(),\n",
        "        #                        horizontal = self.flip_rng())\n",
        "        #transformed = self.rotate(transformed, angle = self.rotation_rng())\n",
        "        #transformed = self.color_twist(transformed, brightness=self.bri_con_rng(),\n",
        "        #                                contrast=self.bri_con_rng(),\n",
        "        #                                saturation=self.saturation_rng())\n",
        "        transformed = self.resize(transformed)\n",
        "        return (transformed, self.labels)\n",
        "\n",
        "    @property\n",
        "    def iter_size(self,):\n",
        "      return self.external_data.size\n",
        "\n",
        "\n",
        "    def iter_setup(self):\n",
        "      try:\n",
        "        (images, labels) = self.iterator.next()\n",
        "        self.feed_input(self.jpegs, images)\n",
        "        self.feed_input(self.labels, labels)\n",
        "      except StopIteration:\n",
        "        self.iterator = iter(self.external_data)\n",
        "        raise StopIteration\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV9Z7HCyodDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_images():\n",
        "    transformations = transforms.Compose([\n",
        "        transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
        "                             0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_pipe = AugmentationPipeline(BATCH_SIZE, 8, examples_per_image=1)\n",
        "    train_pii = PyTorchIterator(train_pipe,\n",
        "                                          size=train_pipe.iter_size,\n",
        "                                          last_batch_padded=True,\n",
        "                                          fill_last_batch=True)\n",
        "    validate_pipe = AugmentationPipeline(BATCH_SIZE, 8, examples_per_image=1)\n",
        "    validate_pii = PyTorchIterator(validate_pipe,\n",
        "                                             size=validate_pipe.iter_size,\n",
        "                                             last_batch_padded=True,\n",
        "                                             fill_last_batch=True)\n",
        "\n",
        "    test_data = datasets.ImageFolder(TEST_DIR, transform=transformations)\n",
        "    num_train = len(test_data)\n",
        "    indices = list(range(num_train))\n",
        "\n",
        "    test_sampler = SubsetRandomSampler(indices)\n",
        "    testloader = torch.utils.data.DataLoader(test_data,\n",
        "                                             sampler=test_sampler, batch_size=64)\n",
        "    dataloaders_dict = {'train':train_pii, 'val' : validate_pii,  'test':testloader}\n",
        "    return dataloaders_dict, {\"train\" : train_pipe.iter_size, \"val\" : validate_pipe.iter_size, \"test\" : num_train}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPlLbD0F3Z5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_labels():\n",
        "    labels = pd.read_csv(FID_LABELS, delimiter=\",\", header=None,\n",
        "                         dtype=np.dtype(int), names=['id', 'label'])\n",
        "    return labels\n",
        "\n",
        "labels = load_labels()\n",
        "\n",
        "\n",
        "def organize_files(label_df):\n",
        "  \"\"\" Moves all pngs in tracked_cropped into subfolders by label (for PyTorch Image Folder) \"\"\"\n",
        "  test_dir = pathlib.Path(TEST_DIR)\n",
        "  files = glob.glob(str(test_dir / \"*.jpg\"))\n",
        "  for i in range(len(files)):\n",
        "    f = pathlib.Path(files[i])\n",
        "    fname = f.name\n",
        "    id = int(f.stem)\n",
        "    label = label_df[\"label\"].iloc[id-1]\n",
        "    new_dir = test_dir / str(label)\n",
        "    new_dir.mkdir(exist_ok=True)\n",
        "    new_file = new_dir / fname\n",
        "    sh.move(f, new_file)\n",
        "\n",
        "organize_files(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8r2lin8ffu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "def train_model(model, dataloaders_info, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "    dataloaders, datasizes = dataloaders_info\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "                inputs, labels = (None, None)\n",
        "                if phase != \"test\":\n",
        "                  inputs = data[0][\"data\"]\n",
        "                  labels = data[0][\"label\"]\n",
        "                else:\n",
        "                  inputs, labels = data \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                if phase != 'test':\n",
        "                    inputs = torch.reshape(inputs,(BATCH_SIZE, 3, INPUT_SIZE, INPUT_SIZE))\n",
        "                    inputs = inputs.float()\n",
        "                    labels = labels.to(torch.int64)\n",
        "                    labels = torch.reshape(labels, (BATCH_SIZE,))\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                torch.cuda.synchronize(device=None)\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            data_size = datasizes[phase]\n",
        "            if phase != \"test\":\n",
        "              dataloaders[phase].reset()\n",
        "\n",
        "\n",
        "\n",
        "            epoch_loss = running_loss / data_size\n",
        "            epoch_acc = float(running_corrects) / data_size\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVv4Imzbn-b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(MODEL_NAME, NUM_CLASSES, FEATURE_EXTRACT=False, USE_PRETRAINED=False):\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if MODEL_NAME == \"resnet\":\n",
        "        model_ft = models.resnet18(pretrained=USE_PRETRAINED)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "        input_size = 224\n",
        "\n",
        "    elif MODEL_NAME == \"alexnet\":\n",
        "        model_ft = models.alexnet(pretrained=USE_PRETRAINED)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,NUM_CLASSES)\n",
        "        input_size = 224\n",
        "\n",
        "    elif MODEL_NAME == \"vgg\":\n",
        "        model_ft = models.vgg11_bn(pretrained=USE_PRETRAINED)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,NUM_CLASSES)\n",
        "        input_size = 224\n",
        "\n",
        "    elif MODEL_NAME == \"squeezenet\":\n",
        "        model_ft = models.squeezenet1_0(pretrained=USE_PRETRAINED)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = NUM_CLASSES\n",
        "        input_size = 224\n",
        "\n",
        "    elif MODEL_NAME == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=USE_PRETRAINED)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "        input_size = 224\n",
        "\n",
        "    elif MODEL_NAME == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=USE_PRETRAINED)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,NUM_CLASSES)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(MODEL_NAME, NUM_CLASSES, \n",
        "                                        FEATURE_EXTRACT, USE_PRETRAINED)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5WMFl8-vTAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRTxs-SivimF",
        "colab_type": "code",
        "outputId": "13a95009-d72f-4eb6-84b2-95a41c4c1d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fetch_FID_300_data()\n",
        "labels = load_labels()\n",
        "organize_files(labels)\n",
        "dataloaders_info = process_images()\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft, hist = train_model(model_ft, dataloaders_info, criterion, optimizer_ft, \n",
        "                             num_epochs=NUM_EPOCHS, is_inception=(MODEL_NAME==\"inception\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FID-300 Database already exists\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 6.6286 Acc: 0.0051\n",
            "val Loss: 6.5210 Acc: 0.0051\n",
            "test Loss: 6.4463 Acc: 0.0033\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 6.4868 Acc: 0.0068\n",
            "val Loss: 6.4008 Acc: 0.0085\n",
            "test Loss: 6.3281 Acc: 0.0000\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 6.3566 Acc: 0.0077\n",
            "val Loss: 6.3110 Acc: 0.0051\n",
            "test Loss: 6.2314 Acc: 0.0000\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 6.2450 Acc: 0.0085\n",
            "val Loss: 6.1957 Acc: 0.0111\n",
            "test Loss: 6.1472 Acc: 0.0000\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 6.1241 Acc: 0.0077\n",
            "val Loss: 6.0789 Acc: 0.0068\n",
            "test Loss: 6.0806 Acc: 0.0000\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 6.0519 Acc: 0.0060\n",
            "val Loss: 6.0716 Acc: 0.0043\n",
            "test Loss: 6.0419 Acc: 0.0000\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 5.9780 Acc: 0.0094\n",
            "val Loss: 5.9654 Acc: 0.0034\n",
            "test Loss: 6.0260 Acc: 0.0000\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 5.8906 Acc: 0.0068\n",
            "val Loss: 5.9124 Acc: 0.0060\n",
            "test Loss: 5.9631 Acc: 0.0000\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 5.8188 Acc: 0.0102\n",
            "val Loss: 5.8271 Acc: 0.0119\n",
            "test Loss: 5.9339 Acc: 0.0000\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 5.7840 Acc: 0.0136\n",
            "val Loss: 5.7289 Acc: 0.0085\n",
            "test Loss: 5.9308 Acc: 0.0000\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 5.6875 Acc: 0.0077\n",
            "val Loss: 5.6860 Acc: 0.0145\n",
            "test Loss: 5.9167 Acc: 0.0000\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 5.6334 Acc: 0.0145\n",
            "val Loss: 5.6673 Acc: 0.0136\n",
            "test Loss: 5.9109 Acc: 0.0000\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 5.5771 Acc: 0.0170\n",
            "val Loss: 5.5627 Acc: 0.0204\n",
            "test Loss: 5.8637 Acc: 0.0000\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 5.5500 Acc: 0.0119\n",
            "val Loss: 5.5706 Acc: 0.0077\n",
            "test Loss: 5.8350 Acc: 0.0067\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 5.5058 Acc: 0.0085\n",
            "val Loss: 5.5201 Acc: 0.0077\n",
            "test Loss: 5.8824 Acc: 0.0000\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 5.4401 Acc: 0.0128\n",
            "val Loss: 5.4733 Acc: 0.0136\n",
            "test Loss: 5.8595 Acc: 0.0000\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 5.4109 Acc: 0.0162\n",
            "val Loss: 5.4704 Acc: 0.0145\n",
            "test Loss: 5.8297 Acc: 0.0200\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 5.3709 Acc: 0.0213\n",
            "val Loss: 5.4002 Acc: 0.0340\n",
            "test Loss: 5.8026 Acc: 0.0000\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 5.3128 Acc: 0.0255\n",
            "val Loss: 5.3618 Acc: 0.0187\n",
            "test Loss: 5.8203 Acc: 0.0000\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 5.3012 Acc: 0.0230\n",
            "val Loss: 5.3242 Acc: 0.0213\n",
            "test Loss: 5.7930 Acc: 0.0100\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 5.2559 Acc: 0.0196\n",
            "val Loss: 5.2382 Acc: 0.0187\n",
            "test Loss: 5.8379 Acc: 0.0033\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 5.2038 Acc: 0.0281\n",
            "val Loss: 5.1927 Acc: 0.0332\n",
            "test Loss: 5.8330 Acc: 0.0000\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 5.1799 Acc: 0.0434\n",
            "val Loss: 5.2801 Acc: 0.0366\n",
            "test Loss: 5.8120 Acc: 0.0000\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 5.1250 Acc: 0.0604\n",
            "val Loss: 5.1409 Acc: 0.0604\n",
            "test Loss: 5.8093 Acc: 0.0000\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 5.0826 Acc: 0.0511\n",
            "val Loss: 5.1831 Acc: 0.0272\n",
            "test Loss: 5.8212 Acc: 0.0000\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 5.0575 Acc: 0.0528\n",
            "val Loss: 5.0800 Acc: 0.0417\n",
            "test Loss: 5.7870 Acc: 0.0000\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 5.0158 Acc: 0.0485\n",
            "val Loss: 5.1023 Acc: 0.0272\n",
            "test Loss: 5.8369 Acc: 0.0000\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 4.9830 Acc: 0.0528\n",
            "val Loss: 5.0542 Acc: 0.0553\n",
            "test Loss: 5.8155 Acc: 0.0200\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 4.9642 Acc: 0.0613\n",
            "val Loss: 5.0422 Acc: 0.0477\n",
            "test Loss: 5.7921 Acc: 0.0033\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 4.9351 Acc: 0.0553\n",
            "val Loss: 4.9474 Acc: 0.0332\n",
            "test Loss: 5.8626 Acc: 0.0100\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 4.8845 Acc: 0.0630\n",
            "val Loss: 4.9683 Acc: 0.0740\n",
            "test Loss: 5.7655 Acc: 0.0100\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 4.8571 Acc: 0.0587\n",
            "val Loss: 4.8409 Acc: 0.0655\n",
            "test Loss: 5.8153 Acc: 0.0000\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 4.8105 Acc: 0.0511\n",
            "val Loss: 4.8804 Acc: 0.0443\n",
            "test Loss: 5.7840 Acc: 0.0100\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 4.7811 Acc: 0.0774\n",
            "val Loss: 4.8049 Acc: 0.1132\n",
            "test Loss: 5.8061 Acc: 0.0100\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 4.7352 Acc: 0.0860\n",
            "val Loss: 4.8038 Acc: 0.0894\n",
            "test Loss: 5.8058 Acc: 0.0000\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 4.6944 Acc: 0.1719\n",
            "val Loss: 4.8685 Acc: 0.1719\n",
            "test Loss: 5.7695 Acc: 0.0067\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 4.6852 Acc: 0.1421\n",
            "val Loss: 4.7980 Acc: 0.0434\n",
            "test Loss: 5.8498 Acc: 0.0000\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 4.6419 Acc: 0.1711\n",
            "val Loss: 4.6881 Acc: 0.2230\n",
            "test Loss: 5.7674 Acc: 0.0033\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhcWioCGFDRc",
        "colab_type": "code",
        "outputId": "eef15fbd-bad5-43a8-e2ed-7b9823d376ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%debug\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:No traceback has been produced, nothing to debug.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}